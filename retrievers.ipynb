{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5f97c8",
   "metadata": {},
   "source": [
    "### PRE-REQUISITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7aaf19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfccdb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a05f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8263948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_dataset = {\n",
    "\n",
    "         \"What is the largest planet in our solar system?\":  \"Jupiter\",\n",
    "         \"Which planet is known as the Red Planet?\": \"Mars\",\n",
    "         \"What is the name of the first human to walk on the moon?\": \"Neil Armstrong\",\n",
    "\n",
    "         \"What does 'API' stand for?\": \"Application Programming Interface\",\n",
    "         \"Which language is primarily used for Android app development in 2026?\": \"Kotlin\",\n",
    "         \"What is a 'boolean' in programming?\": \"A data type that has one of two possible values: true or false.\",\n",
    "\n",
    "         \"What is the main ingredient in traditional guacamole?\": \"Avocado\",\n",
    "         \"What does the French term 'Sous-vide' mean?\": \"Under vacuum\",\n",
    "         \"Which spice is known as the most expensive in the world?\": \"Saffron\",\n",
    "\n",
    "         \"What is the primary greenhouse gas emitted by human activities?\": \"Carbon dioxide (CO2)\",\n",
    "         \"What process do plants use to convert sunlight into energy?\": \"Photosynthesis\",\n",
    "         \"What is the term for the variety of life in a particular habitat?\": \"Biodiversity\",\n",
    " \n",
    "         \"In what year did the French Revolution begin?\": \"1789\",\n",
    "         \"Who was the first female Prime Minister of the United Kingdom?\": \"Margaret Thatcher\",\n",
    "         \"Which ancient civilization built the Great Pyramid of Giza?\": \"The Egyptians\",\n",
    "         \n",
    "         \"Which of the planets in our galaxy has the most massive size?\":\"Jupiter\",\n",
    "         \"What is the variable type that only holds true or false data?\":\"A data type that has one of two possible values: true or false.\",\n",
    "          \"Can you tell me the primary component used to make standard guacamole?\":\"Avocado\",\n",
    "          \"How do we define the total variety of different species in a specific ecosystem?\":\"Biodiversity\",\n",
    "          \"Which group of ancient people was responsible for constructing the Giza pyramids?\":\"The Egyptians\"\n",
    "          \n",
    "         \n",
    "          \n",
    "          \n",
    "         \n",
    "}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca5b92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "\n",
    "for question, answer in qa_dataset.items():\n",
    "    d=Document(page_content=question, metadata={\"answer\": answer})\n",
    "    docs.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51a612fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  initialize FAISS vector store\n",
    "vector_store = FAISS.from_documents(documents=docs, embedding=embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406fa45",
   "metadata": {},
   "source": [
    "## Retrivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c7ac4",
   "metadata": {},
   "source": [
    "1. Vector store as retriever\n",
    "2. Similarity Score Threshold retriever \n",
    "3. MMR(Maximal Marginal Relevance) retriever\n",
    "4. Multi-Query retriever\n",
    "5. Contextual Compression Retriever\n",
    "6. Data source specific retriever [Wikipedia retriver, Arxiv retriver, vectrostore retriver]\n",
    "7. ParentDocumentRetriever\n",
    "8. MultiVectorretriever\n",
    "9. SelfQueryRetriever\n",
    "10. EnsembleRetriever\n",
    "11. TimeWeightedRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352e107",
   "metadata": {},
   "source": [
    "#### Q) If vector database  only provide method to get relevent documents then why retrivers required?\n",
    "- Yes vector store provide one method to get relevant documents, but retrivers add more functionality to it, hence retrivers also required "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ec03a",
   "metadata": {},
   "source": [
    "### 1. Vector store as retriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3578df",
   "metadata": {},
   "source": [
    "- Uses cosine similarity to find relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fd597e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n",
      "Answer: Jupiter\n",
      "\n",
      "Question: Which of the planets in our galaxy has the most massive size?\n",
      "Answer: Jupiter\n",
      "\n",
      "Question: Which planet is known as the Red Planet?\n",
      "Answer: Mars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retriver\n",
    "retriever=vector_store.as_retriever()\n",
    "\n",
    "\n",
    "# sample query\n",
    "user_question=\"What is the largest planet in our solar system?\"\n",
    "\n",
    "# retrieve top 3 similar questions\n",
    "retrieved_docs = retriever.invoke(user_question,k=3)\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"Question: {doc.page_content}\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44f163d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 1.0000\n",
      "Question: What is the largest planet in our solar system?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Similarity Score: 0.6320\n",
      "Question: Which of the planets in our galaxy has the most massive size?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Similarity Score: 0.4032\n",
      "Question: Which planet is known as the Red Planet?\n",
      "\n",
      "Answer: Mars\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  get result along with similarity score\n",
    "results = vector_store.similarity_search_with_relevance_scores(user_question, k=3)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Question: {doc.page_content}\\n\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")\n",
    "    print(\"-----\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a525a7bb",
   "metadata": {},
   "source": [
    "### 2. Similarity Score Threshold retriever \n",
    "\n",
    "**Working Principle:** Same as vector store as retriver but here we can add similarity threshold, the documnets with lesser similarity than given threshold will not fetched\n",
    "\n",
    "**Advantaged:** It takes only highly related documents only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77ced58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Which of the planets in our galaxy has the most massive size?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# retriver\n",
    "retriever_with_threshold = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.5}  # u can play with threshold value\n",
    ")\n",
    "# Only returns matches >80% similar\n",
    "\n",
    "\n",
    "# sample query\n",
    "user_question=\"What is the largest planet in our solar system?\"\n",
    "\n",
    "#  get result along with similarity score\n",
    "results = retriever_with_threshold.invoke(user_question)\n",
    "\n",
    "for doc in results:\n",
    "    # print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Question: {doc.page_content}\\n\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")\n",
    "    print(\"-----\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565ce85",
   "metadata": {},
   "source": [
    "### 3. MMR(Maximal Marginal Relevance) \n",
    "**Working Principles:**\n",
    "- Designed to reduce redundancy in the retrieved result while Maintains high relevancy to the query\n",
    "- Picks most relevant document first\n",
    "- Then select next most relevant document and least relevant to the already selected document\n",
    "\n",
    "**Advantages:**\n",
    "- Reduce the repeating of same information\n",
    "- Enhance the the diversity in the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9856d",
   "metadata": {},
   "source": [
    "#### MMR Search Keyword Definitions\n",
    "\n",
    "*   **`k: 3` (The Final Count)**\n",
    "    *   This is the total number of documents that will ultimately be returned to you. Even if the AI finds 50 relevant items, it will output only the **top 3** most diverse and relevant ones.\n",
    "\n",
    "*   **`fetch_k: 10` (The Initial Pool)**\n",
    "    *   The retriever first grabs the **10** most similar documents based purely on cosine similarity.\n",
    "    *   **Why?** MMR needs a \"candidate pool\" to evaluate and compare for diversity.\n",
    "    *   **Rule of Thumb:** Always set `fetch_k` significantly higher than `k` (usually 3x or 4x).\n",
    "\n",
    "*   **`lambda_mult: 0.5` (The Diversity Slider)**\n",
    "    *   This is the \"magic\" number that balances **Similarity vs. Diversity** on a scale of **0.0 to 1.0**:\n",
    "        *   **1.0 (Pure Similarity):** Acts exactly like a standard similarity search; it does not prioritize diversity.\n",
    "        *   **0.5 (Balanced):** The default setting. It looks for documents that are highly relevant but also \"different\" from one another.\n",
    "        *   **0.0 (Pure Diversity):** Prioritizes results that are as unique as possible from each other, even if they aren't the absolute closest matches to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ddd6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Which ancient civilization built the Great Pyramid of Giza?\n",
      "\n",
      "Answer: The Egyptians\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Who was the first female Prime Minister of the United Kingdom?\n",
      "\n",
      "Answer: Margaret Thatcher\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mmr_retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.1}\n",
    ")\n",
    "# fetch_k=10 (wide net), k=3 (final diverse results)\n",
    "\n",
    "\n",
    "# sample query\n",
    "user_question=\"What is the largest planet in our solar system?\"\n",
    "\n",
    "#  get result\n",
    "results = mmr_retriever.invoke(user_question)\n",
    "\n",
    "for doc in results:\n",
    "    # print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Question: {doc.page_content}\\n\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")\n",
    "    print(\"-----\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93805cfb",
   "metadata": {},
   "source": [
    "### 4. Multi-Query retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463bc46",
   "metadata": {},
   "source": [
    "**Working principle:**\n",
    "- For give query it generates some more relevent querries using llm\n",
    "- For each generated querries, it fetch the relevent document from the vector store\n",
    "- out of all featched documents fetch the top k most relevant querries\n",
    "\n",
    "**Advantages:**\n",
    "- Increase the recall of the query\n",
    "\n",
    "**Example:**\n",
    "\n",
    "User Query: \"How do neural networks work?\"\n",
    "\n",
    "↓ LLM Query Generator\n",
    "\n",
    "3 Variations:\n",
    "1. \"Explain neural network functionality\"\n",
    "2. \"Mechanism of neural networks\"  \n",
    "3. \"How do NNs process information?\"\n",
    "\n",
    "↓ Similarity Search (ALL 3 queries)\n",
    "\n",
    "↓ Combine + De-duplicate Results\n",
    "\n",
    "↓ Return diverse, comprehensive documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a977a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\RAG\\RAG_ENV\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_classic.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7575055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup vector store with diverse docs\n",
    "docs = [\n",
    "    Document(page_content=\"Neural networks process data through layers of interconnected nodes\"),\n",
    "    Document(page_content=\"Deep learning models use backpropagation for training\"),\n",
    "    Document(page_content=\"Transformers revolutionized sequence modeling\"),\n",
    "    Document(page_content=\"CNNs excel at image recognition tasks\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371954cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2967e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# ✅ CORRECT for latest LangChain\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb4b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Test it\n",
    "user_query = \"How do neural networks work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fc8f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTIQUERY RESULTS ===\n",
      "1. Neural networks process data through layers of interconnected nodes\n",
      "2. Deep learning models use backpropagation for training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = multi_query_retriever.invoke(user_query)\n",
    "\n",
    "print(\"=== MULTIQUERY RESULTS ===\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f30b4d",
   "metadata": {},
   "source": [
    "### 5. Contextual Compression Retriever\n",
    "**Working Principle:**\n",
    "- Retreive document as same as similarity rearch\n",
    "- But while returning the result , it remove the unwanted content in each document\n",
    "\n",
    "**Advantage:**\n",
    "- Only related content will be available for llm\n",
    "- Improve the accuracy of generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7565177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers import ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ddad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"Neural networks process data through layers of interconnected nodes. Tiger is that national animal of india\"),\n",
    "    Document(page_content=\"Deep learning models use backpropagation for training. Deer run very fast\"),\n",
    "    Document(page_content=\"Transformers revolutionized sequence modeling. I love india\"),\n",
    "    Document(page_content=\"CNNs excel at image recognition tasks. Elephant is the largest land animal\")\n",
    "]\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b17b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da63afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)  # LLM decides what to keep\n",
    "\n",
    "base_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d628742",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c652284",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs=compression_retriever.invoke(\"which network used in image recognisition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13c62178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='CNNs excel at image recognition tasks.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa743769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There are many techniques available for compressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7531f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
