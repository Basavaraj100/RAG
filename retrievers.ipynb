{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5f97c8",
   "metadata": {},
   "source": [
    "### PRE-REQUISITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7aaf19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfccdb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a05f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8263948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_dataset = {\n",
    "\n",
    "         \"What is the largest planet in our solar system?\":  \"Jupiter\",\n",
    "         \"Which planet is known as the Red Planet?\": \"Mars\",\n",
    "         \"What is the name of the first human to walk on the moon?\": \"Neil Armstrong\",\n",
    "\n",
    "         \"What does 'API' stand for?\": \"Application Programming Interface\",\n",
    "         \"Which language is primarily used for Android app development in 2026?\": \"Kotlin\",\n",
    "         \"What is a 'boolean' in programming?\": \"A data type that has one of two possible values: true or false.\",\n",
    "\n",
    "         \"What is the main ingredient in traditional guacamole?\": \"Avocado\",\n",
    "         \"What does the French term 'Sous-vide' mean?\": \"Under vacuum\",\n",
    "         \"Which spice is known as the most expensive in the world?\": \"Saffron\",\n",
    "\n",
    "         \"What is the primary greenhouse gas emitted by human activities?\": \"Carbon dioxide (CO2)\",\n",
    "         \"What process do plants use to convert sunlight into energy?\": \"Photosynthesis\",\n",
    "         \"What is the term for the variety of life in a particular habitat?\": \"Biodiversity\",\n",
    " \n",
    "         \"In what year did the French Revolution begin?\": \"1789\",\n",
    "         \"Who was the first female Prime Minister of the United Kingdom?\": \"Margaret Thatcher\",\n",
    "         \"Which ancient civilization built the Great Pyramid of Giza?\": \"The Egyptians\",\n",
    "         \n",
    "         \"Which of the planets in our galaxy has the most massive size?\":\"Jupiter\",\n",
    "         \"What is the variable type that only holds true or false data?\":\"A data type that has one of two possible values: true or false.\",\n",
    "          \"Can you tell me the primary component used to make standard guacamole?\":\"Avocado\",\n",
    "          \"How do we define the total variety of different species in a specific ecosystem?\":\"Biodiversity\",\n",
    "          \"Which group of ancient people was responsible for constructing the Giza pyramids?\":\"The Egyptians\"\n",
    "          \n",
    "         \n",
    "          \n",
    "          \n",
    "         \n",
    "}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca5b92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "\n",
    "for question, answer in qa_dataset.items():\n",
    "    d=Document(page_content=question, metadata={\"answer\": answer})\n",
    "    docs.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51a612fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  initialize FAISS vector store\n",
    "vector_store = FAISS.from_documents(documents=docs, embedding=embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406fa45",
   "metadata": {},
   "source": [
    "## Retrivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c7ac4",
   "metadata": {},
   "source": [
    "1. Vector store as retriever\n",
    "2. Similarity Score Threshold retriever \n",
    "3. MMR(Maximal Marginal Relevance) retriever\n",
    "4. Multi-Query retriever\n",
    "5. Contextual Compression Retriever\n",
    "6. Data source specific retriever [Wikipedia retriver, Arxiv retriver, vectrostore retriver]\n",
    "7. ParentDocumentRetriever\n",
    "8. MultiVectorretriever\n",
    "9. SelfQueryRetriever\n",
    "10. EnsembleRetriever\n",
    "11. TimeWeightedRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352e107",
   "metadata": {},
   "source": [
    "#### Q) If vector database  only provide method to get relevent documents then why retrivers required?\n",
    "- Yes vector store provide one method to get relevant documents, but retrivers add more functionality to it, hence retrivers also required "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ec03a",
   "metadata": {},
   "source": [
    "### 1. Vector store as retriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3578df",
   "metadata": {},
   "source": [
    "- Uses cosine similarity to find relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fd597e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n",
      "Answer: Jupiter\n",
      "\n",
      "Question: Which of the planets in our galaxy has the most massive size?\n",
      "Answer: Jupiter\n",
      "\n",
      "Question: Which planet is known as the Red Planet?\n",
      "Answer: Mars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retriver\n",
    "retriever=vector_store.as_retriever()\n",
    "\n",
    "\n",
    "# sample query\n",
    "user_question=\"What is the largest planet in our solar system?\"\n",
    "\n",
    "# retrieve top 3 similar questions\n",
    "retrieved_docs = retriever.invoke(user_question,k=3)\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"Question: {doc.page_content}\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44f163d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 1.0000\n",
      "Question: What is the largest planet in our solar system?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Similarity Score: 0.6320\n",
      "Question: Which of the planets in our galaxy has the most massive size?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Similarity Score: 0.4032\n",
      "Question: Which planet is known as the Red Planet?\n",
      "\n",
      "Answer: Mars\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#  get result along with similarity score\n",
    "results = vector_store.similarity_search_with_relevance_scores(user_question, k=3)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Question: {doc.page_content}\\n\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")\n",
    "    print(\"-----\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a525a7bb",
   "metadata": {},
   "source": [
    "### 2. Similarity Score Threshold retriever \n",
    "\n",
    "**Working Principle:** Same as vector store as retriver but here we can add similarity threshold, the documnets with lesser similarity than given threshold will not fetched\n",
    "\n",
    "**Advantaged:** It takes only highly related documents only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77ced58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Which of the planets in our galaxy has the most massive size?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# retriver\n",
    "retriever_with_threshold = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.5}  # u can play with threshold value\n",
    ")\n",
    "# Only returns matches >80% similar\n",
    "\n",
    "\n",
    "# sample query\n",
    "user_question=\"What is the largest planet in our solar system?\"\n",
    "\n",
    "#  get result along with similarity score\n",
    "results = retriever_with_threshold.invoke(user_question)\n",
    "\n",
    "for doc in results:\n",
    "    # print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Question: {doc.page_content}\\n\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")\n",
    "    print(\"-----\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565ce85",
   "metadata": {},
   "source": [
    "### 3. MMR(Maximal Marginal Relevance) \n",
    "**Working Principles:**\n",
    "- Designed to reduce redundancy in the retrieved result while Maintains high relevancy to the query\n",
    "- Picks most relevant document first\n",
    "- Then select next most relevant document and least relevant to the already selected document\n",
    "\n",
    "**Advantages:**\n",
    "- Reduce the repeating of same information\n",
    "- Enhance the the diversity in the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9856d",
   "metadata": {},
   "source": [
    "#### MMR Search Keyword Definitions\n",
    "\n",
    "*   **`k: 3` (The Final Count)**\n",
    "    *   This is the total number of documents that will ultimately be returned to you. Even if the AI finds 50 relevant items, it will output only the **top 3** most diverse and relevant ones.\n",
    "\n",
    "*   **`fetch_k: 10` (The Initial Pool)**\n",
    "    *   The retriever first grabs the **10** most similar documents based purely on cosine similarity.\n",
    "    *   **Why?** MMR needs a \"candidate pool\" to evaluate and compare for diversity.\n",
    "    *   **Rule of Thumb:** Always set `fetch_k` significantly higher than `k` (usually 3x or 4x).\n",
    "\n",
    "*   **`lambda_mult: 0.5` (The Diversity Slider)**\n",
    "    *   This is the \"magic\" number that balances **Similarity vs. Diversity** on a scale of **0.0 to 1.0**:\n",
    "        *   **1.0 (Pure Similarity):** Acts exactly like a standard similarity search; it does not prioritize diversity.\n",
    "        *   **0.5 (Balanced):** The default setting. It looks for documents that are highly relevant but also \"different\" from one another.\n",
    "        *   **0.0 (Pure Diversity):** Prioritizes results that are as unique as possible from each other, even if they aren't the absolute closest matches to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ddd6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n",
      "\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Which ancient civilization built the Great Pyramid of Giza?\n",
      "\n",
      "Answer: The Egyptians\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Who was the first female Prime Minister of the United Kingdom?\n",
      "\n",
      "Answer: Margaret Thatcher\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mmr_retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.1}\n",
    ")\n",
    "# fetch_k=10 (wide net), k=3 (final diverse results)\n",
    "\n",
    "\n",
    "# sample query\n",
    "user_question=\"What is the largest planet in our solar system?\"\n",
    "\n",
    "#  get result\n",
    "results = mmr_retriever.invoke(user_question)\n",
    "\n",
    "for doc in results:\n",
    "    # print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Question: {doc.page_content}\\n\")\n",
    "    print(f\"Answer: {doc.metadata['answer']}\\n\")\n",
    "    print(\"-----\"*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93805cfb",
   "metadata": {},
   "source": [
    "### 4. Multi-Query retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463bc46",
   "metadata": {},
   "source": [
    "**Working principle:**\n",
    "- For give query it generates some more relevent querries using llm\n",
    "- For each generated querries, it fetch the relevent document from the vector store\n",
    "- out of all featched documents fetch the top k most relevant querries\n",
    "\n",
    "**Advantages:**\n",
    "- Increase the recall of the query\n",
    "\n",
    "**Example:**\n",
    "\n",
    "User Query: \"How do neural networks work?\"\n",
    "\n",
    "â†“ LLM Query Generator\n",
    "\n",
    "3 Variations:\n",
    "1. \"Explain neural network functionality\"\n",
    "2. \"Mechanism of neural networks\"  \n",
    "3. \"How do NNs process information?\"\n",
    "\n",
    "â†“ Similarity Search (ALL 3 queries)\n",
    "\n",
    "â†“ Combine + De-duplicate Results\n",
    "\n",
    "â†“ Return diverse, comprehensive documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a977a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\RAG\\RAG_ENV\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_classic.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7575055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup vector store with diverse docs\n",
    "docs = [\n",
    "    Document(page_content=\"Neural networks process data through layers of interconnected nodes\"),\n",
    "    Document(page_content=\"Deep learning models use backpropagation for training\"),\n",
    "    Document(page_content=\"Transformers revolutionized sequence modeling\"),\n",
    "    Document(page_content=\"CNNs excel at image recognition tasks\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371954cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2967e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# âœ… CORRECT for latest LangChain\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb4b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Test it\n",
    "user_query = \"How do neural networks work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fc8f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTIQUERY RESULTS ===\n",
      "1. Neural networks process data through layers of interconnected nodes\n",
      "2. Deep learning models use backpropagation for training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = multi_query_retriever.invoke(user_query)\n",
    "\n",
    "print(\"=== MULTIQUERY RESULTS ===\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f30b4d",
   "metadata": {},
   "source": [
    "### 5. Contextual Compression Retriever\n",
    "**Working Principle:**\n",
    "- Retreive document as same as similarity rearch\n",
    "- But while returning the result , it remove the unwanted content in each document\n",
    "\n",
    "**Advantage:**\n",
    "- Only related content will be available for llm\n",
    "- Improve the accuracy of generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7565177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers import ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ddad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"Neural networks process data through layers of interconnected nodes. Tiger is that national animal of india\"),\n",
    "    Document(page_content=\"Deep learning models use backpropagation for training. Deer run very fast\"),\n",
    "    Document(page_content=\"Transformers revolutionized sequence modeling. I love india\"),\n",
    "    Document(page_content=\"CNNs excel at image recognition tasks. Elephant is the largest land animal\")\n",
    "]\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b17b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da63afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)  # LLM decides what to keep\n",
    "\n",
    "base_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d628742",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c652284",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs=compression_retriever.invoke(\"which network used in image recognisition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13c62178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='CNNs excel at image recognition tasks.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa743769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There are many techniques available for compressor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f703962",
   "metadata": {},
   "source": [
    "### 6. Data source specific retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7531f",
   "metadata": {},
   "source": [
    "#### 6.2 Wikipedia Retriever  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec7c2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "retriever = WikipediaRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "954264ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_content=retriever.invoke(\"IPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "674c4bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian Premier League (IPL) is a professional Twenty20 (T20) cricket league in India, organised by the Board of Control for Cricket in India (BCCI). Founded in 2007, it features ten city-based franchise teams. The IPL is the most popular and richest cricket league in the world and the 13th richest sporting league in the world by revenue. It is held annually between March and May. It has an exclusive window in the Future Tours Programme of the International Cricket Council, resulting in fewer international tours occurring during the seasons. It is also the most viewed Indian sports event, per the Broadcast Audience Research Council.\\nIn 2010, the IPL became the first sporting event to broadcast live on YouTube. In 2014, it ranked sixth in attendance among all sports leagues. Inspired by the success of the IPL, other Indian sports leagues have been established. The IPL is the second-richest sports league in the world by per-match value, after the National Football League. In 2023, the league sold its media rights for the next four seasons for US$6.4 billion to Viacom18 and Star Sports, which meant that each IPL match was valued at $13.4 million. As of 2025, there have been 18 seasons of the tournament. The current champions are the Royal Challengers Bengaluru, who won the 2025 season after defeating the Punjab Kings in the final.\\nA women\\'s edition of the Indian Premier League, known as the Women\\'s Premier League, was established in 2022 and had its first season in 2023.\\n\\n\\n== History ==\\n\\n\\n=== Background ===\\nIn April 2007, Essel Group launched the Indian Cricket League (ICL) in partnership with IL&FS. The ICL was not recognized by the Board of Control for Cricket in India (BCCI) or the International Cricket Council (ICC). Moreover, the BCCI was unhappy about its committee members joining the ICL executive board. In response, the BCCI increased the prize money for its domestic tournaments and imposed lifetime bans on players who joined the ICL, which it considered a rebel league.\\n\\n\\n=== Foundation ===\\nOn 13 September 2007, as the 2007 ICC World Twenty20 began, the BCCI launched the Indian Premier League, an annual franchise-based Twenty20 cricket competition. The inaugural season was scheduled to start in April 2008, commencing with a \"high-profile ceremony\" in New Delhi. BCCI vice-president Lalit Modi, who led the IPL initiative, provided details of the tournament, including its format, prize money, franchise revenue system, and squad composition rules. The league, to be managed by a seven-person governing council, would also serve as the qualifying mechanism for that year\\'s Champions League Twenty20.\\nTo determine team ownership, an auction for the franchises was held on 24 January 2008. The reserve prices for the eight franchises totalled $400 million, but the auction ultimately raised $723.59 million. The league officially commenced in April 2008, featuring Chennai Super Kings (CSK), Mumbai Indians (MI), Delhi Daredevils (DD), Kings XI Punjab (KXIP), Deccan Chargers (DC), Rajasthan Royals (RR), Kolkata Knight Riders (KKR), and Royal Challengers Bangalore (RCB).\\nIn 2009, the BCCI and other national boards offered amnesty to rival ICL\\'s players and officials, provided they terminated their contracts. The resulting player exodus and financial difficulties forced ICL to shut down later that year.\\n\\n\\n=== Expansions and terminations ===\\nNew franchises, Pune Warriors India and Kochi Tuskers Kerala, joined the league before the fourth season in 2011. The Sahara Adventure Sports Group purchased the Pune franchise for $370 million, while Rendezvous Sports World bought the Kochi franchise for $333.3 million. The Kochi franchise was terminated after just one season due to their failure to pay the BCCI the 10% bank guarantee element of the franchise fee.\\nIn September 2012, the Deccan Chargers franchise agreement was terminated after the BCCI failed to find new owners. In October, an auction was held for a replacement franchise; Sun TV Netwo'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_content[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c34e0f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Indian Premier League',\n",
       " 'summary': \"The Indian Premier League (IPL) is a professional Twenty20 (T20) cricket league in India, organised by the Board of Control for Cricket in India (BCCI). Founded in 2007, it features ten city-based franchise teams. The IPL is the most popular and richest cricket league in the world and the 13th richest sporting league in the world by revenue. It is held annually between March and May. It has an exclusive window in the Future Tours Programme of the International Cricket Council, resulting in fewer international tours occurring during the seasons. It is also the most viewed Indian sports event, per the Broadcast Audience Research Council.\\nIn 2010, the IPL became the first sporting event to broadcast live on YouTube. In 2014, it ranked sixth in attendance among all sports leagues. Inspired by the success of the IPL, other Indian sports leagues have been established. The IPL is the second-richest sports league in the world by per-match value, after the National Football League. In 2023, the league sold its media rights for the next four seasons for US$6.4 billion to Viacom18 and Star Sports, which meant that each IPL match was valued at $13.4 million. As of 2025, there have been 18 seasons of the tournament. The current champions are the Royal Challengers Bengaluru, who won the 2025 season after defeating the Punjab Kings in the final.\\nA women's edition of the Indian Premier League, known as the Women's Premier League, was established in 2022 and had its first season in 2023.\",\n",
       " 'source': 'https://en.wikipedia.org/wiki/Indian_Premier_League'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_content[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a696b",
   "metadata": {},
   "source": [
    "### 7. ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c6fe3",
   "metadata": {},
   "source": [
    "â€¢ **Input**: Long documents (2000+ tokens each)\n",
    "\n",
    "â€¢ **Parent Splitter**: \n",
    "  â”œâ”€ Breaks docs into large chunks (ex: 2000 tokens)\n",
    "  â””â”€ Stores these PARENT chunks in docstore with UUIDs\n",
    "\n",
    "â€¢ **Child Splitter**: \n",
    "  â”œâ”€ Breaks SAME docs into small chunks (ex: 400 tokens)  \n",
    "  â””â”€ Indexes ALL child chunks in vectorstore\n",
    "\n",
    "â€¢ **Child Metadata**: Each child chunk stores `parent_id` UUID\n",
    "\n",
    "â€¢ **Query Time**:\n",
    "  â”œâ”€ Query â†’ similarity search on child chunks (precise matching)\n",
    "  â”œâ”€ Get top-k child chunks\n",
    "  â”œâ”€ Extract parent_id from child metadata  \n",
    "  â””â”€ Return FULL parent documents from docstore\n",
    "\n",
    "â€¢ **Output**: Large parent documents (rich context) \n",
    "  â””â”€ Despite precise child-chunk retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca80a7b",
   "metadata": {},
   "source": [
    "### 8. MultiVectorretriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e9312",
   "metadata": {},
   "source": [
    "â€¢ **Input**: Single document (table, text, image+caption, etc.)\n",
    "\n",
    "â€¢ **Generate Multiple Representations**:\n",
    "  â”œâ”€ Text summary (broad semantic search)\n",
    "  â”œâ”€ Small text chunks (precise matching)  \n",
    "  â”œâ”€ Hypothetical questions (query simulation)\n",
    "  â””â”€ Image embeddings/captions (multi-modal)\n",
    "\n",
    "â€¢ **Indexing Phase**:\n",
    "  â”œâ”€ Embed ALL representations â†’ vectorstore\n",
    "  â”œâ”€ Store ORIGINAL document in docstore with UUID\n",
    "  â””â”€ Link each representation: metadata[\"doc_id\"] = UUID\n",
    "\n",
    "â€¢ **Query Phase**:\n",
    "  â”œâ”€ User query â†’ similarity search across ALL representations\n",
    "  â”œâ”€ ANY matching representation triggers retrieval\n",
    "  â”œâ”€ Extract doc_id from matched representation's metadata\n",
    "  â””â”€ Return COMPLETE original document from docstore\n",
    "\n",
    "â€¢ **Storage**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eebd9f",
   "metadata": {},
   "source": [
    "### 9. SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb8f937",
   "metadata": {},
   "source": [
    "**Input**: Natural language query with metadata conditions  \n",
    "  â””â”€ \"Nolan movies from 2010s rated above 8\"\n",
    "\n",
    "â€¢ **LLM Query Decomposer**:\n",
    "  â”œâ”€ **Extracts structured filters** from natural language\n",
    "  â”œâ”€ **Identifies semantic content** for vector search\n",
    "  â””â”€ **Separates metadata conditions** (director, year, rating)\n",
    "\n",
    "â€¢ **Generated Structured Query**:\n",
    "{\n",
    "\"semantic_query\": \"Nolan movies\",\n",
    "\"filter\": {\n",
    "\"and\": [\n",
    "{\"equals\": {\"key\": \"director\", \"value\": \"Christopher Nolan\"}},\n",
    "{\"gte\": {\"key\": \"year\", \"value\": 2010}},\n",
    "{\"gte\": {\"key\": \"rating\", \"value\": 8}}\n",
    "]\n",
    "}\n",
    "}\n",
    "\n",
    "text\n",
    "\n",
    "â€¢ **Hybrid Retrieval**:\n",
    "  â”œâ”€ **Vector search**: semantic_query on document content\n",
    "  â”œâ”€ **Metadata filter**: Apply exact structured filters\n",
    "  â””â”€ **Intersection**: Combine semantic + metadata results\n",
    "\n",
    "â€¢ **Vectorstore Operations**:\n",
    "ALL docs â†’ semantic search(\"Nolan movies\") â†’ [doc1, doc2, doc3]\n",
    "â†“\n",
    "Apply filter: director=\"Nolan\" AND year>=2010 AND rating>=8\n",
    "â†“\n",
    "Return: [doc1] â† Perfect match!\n",
    "\n",
    "text\n",
    "\n",
    "â€¢ **Key Components**:\n",
    "  â”œâ”€ AttributeInfo schema defines searchable metadata fields\n",
    "  â”œâ”€ LLM translates English â†’ structured query language\n",
    "  â””â”€ Vectorstore supports metadata filtering (FAISS/Chroma/etc.)\n",
    "\n",
    "â€¢ **Output**: Precisely filtered documents matching ALL conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816cf6d2",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "### 10.Ensemble Retrievers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f520ca1",
   "metadata": {},
   "source": [
    "â€¢ **Input**: Query + List of retrievers (2-5 typically)\n",
    "\n",
    "â€¢ **Parallel Execution**:\n",
    "  â”œâ”€ Retriever 1 â†’ [docA, docB, docC]\n",
    "  â”œâ”€ Retriever 2 â†’ [docB, docD, docA]  \n",
    "  â””â”€ Retriever 3 â†’ [docA, docC]\n",
    "\n",
    "â€¢ **Rank Fusion (RRF)**:\n",
    "  â”œâ”€ Each doc gets score from EVERY retriever it appears in\n",
    "  â”œâ”€ RRF: score = 1/(rank + 60) per retriever\n",
    "  â””â”€ Final score = weighted sum across all retrievers\n",
    "\n",
    "â€¢ **Output**: Single unified ranked list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6acf996",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# ğŸ† COMPLETE LANGCHAIN RETRIEVER COMPARISON TABLE\n",
    "\n",
    "| Retriever | Advantages | Disadvantages | When To Use |\n",
    "|-----------|------------|---------------|-------------|\n",
    "| **1. VectorStoreRetriever** | âœ… Fast<br>âœ… Simple<br>âœ… Semantic search | âŒ No filtering<br>âŒ Keyword blind<br>âŒ No diversity | Basic semantic RAG, small datasets |\n",
    "| **2. Similarity Score Threshold** | âœ… High precision<br>âœ… Confidence filtering<br>âœ… No noise | âŒ Zero results possible<br>âŒ Strict cutoff | High accuracy needed, known good threshold |\n",
    "| **3. MMR Retriever** | âœ… Diverse results<br>âœ… Relevance + variety<br>âœ… Production ready | âŒ Slightly slower<br>âŒ Complex params | Avoid redundant docs, exploratory search |\n",
    "| **4. MultiQueryRetriever** | âœ… Higher recall<br>âœ… Query rewriting<br>âœ… Handles ambiguity | âŒ LLM cost (Ã—3-5)<br>âŒ Slower | Low single-query recall, complex questions |\n",
    "| **5. ContextualCompression** | âœ… 70% token savings<br>âœ… Higher LLM accuracy<br>âœ… Production essential | âŒ LLM cost<br>âŒ Slower retrieval | Token optimization, noisy retrieval |\n",
    "| **6. Data Source Specific** | âœ… Fresh data<br>âœ… Specialized APIs<br>âœ… Real-time | âŒ External API calls<br>âŒ Rate limits<br>âŒ Dependency | Live data (Wikipedia, Arxiv, web) |\n",
    "| **7. ParentDocumentRetriever** | âœ… Precision + context<br>âœ… Long docs perfect<br>âœ… Scalable | âŒ Complex setup<br>âŒ Storage Ã—2 | Long technical docs, research papers |\n",
    "| **8. MultiVectorRetriever** | âœ… Multi-modal<br>âœ… Tables/images<br>âœ… Multiple entry points | âŒ Complex indexing<br>âŒ LLM for summaries | Mixed content (tables+text+images) |\n",
    "| **9. SelfQueryRetriever** | âœ… Natural language filters<br>âœ… Metadata precision<br>âœ… User-friendly | âŒ Metadata required<br>âŒ LLM dependent | Structured metadata (author, date, tags) |\n",
    "| **10. EnsembleRetriever** | âœ… Hybrid power<br>âœ… Semantic+keyword<br>âœ… Production gold | âŒ Multiple retrievers<br>âŒ Tuning weights | Production RAG, maximum recall |\n",
    "| **11. TimeWeightedRetriever** | âœ… Freshness aware<br>âœ… Dynamic content<br>âœ… Auto-updates | âŒ Timestamp metadata<br>âŒ Recency bias | Chat history, news, live updates |\n",
    "\n",
    "## **PRODUCTION PRIORITIES** ğŸ”¥\n",
    "\n",
    "- EnsembleRetriever (semantic+BM25) â† MAX RECALL\n",
    "\n",
    "- ContextualCompression â† TOKEN SAVINGS\n",
    "\n",
    "- ParentDocumentRetriever â† LONG DOCS\n",
    "\n",
    "- MultiQueryRetriever â† COMPLEX QUERIES\n",
    "\n",
    "- TimeWeightedRetriever â† FRESH CONTENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20716b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
